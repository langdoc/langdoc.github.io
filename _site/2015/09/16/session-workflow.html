<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Data workflow for linguistic fieldwork</title>
    <meta name="description" content="">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://langdoc.github.io/2015/09/16/session-workflow.html">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Language Documentation</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

<a href="https://github.com/langdoc"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://camo.githubusercontent.com/82b228a3648bf44fc1163ef44c62fcc60081495e/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f6c6566745f7265645f6161303030302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_left_red_aa0000.png"></a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
          <a class="page-link" href="/categories.html">Categories</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/search/">Search</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        


<div class="post">

  <header class="post-header">
    <h1 class="post-title">Data workflow for linguistic fieldwork</h1>
    <p class="post-meta">Sep 16, 2015 • Niko Partanen</p>
  </header>

  <article class="post-content">
    <p>I think quite a lot has been written about the data management workflows in documentary linguistics. Lots of this is about the whole workflow from field to the archive. I want to document here the workflow I’ve personally found very good for the immediate work on the field, and also desire to use later. This doesn’t even touch the issues of annotating, archiving, publishing or disseminating. <strong>I want to stress that this all is something that in my opinion should be done already at the field. Period. Don’t delay it, the consequences are heavy.</strong><!--more--></p>

<p>I’ve encountered occasionally an idea that taking part into a workflow such as presented here would be a sort of a choice. However, you are already there <strong>if</strong> you decide to involve both video and audio into your working practices. The moment you decide to bring a videocamera on the field dictates some aspects from your further workflow as well, as it has to take into account the existence of both audio and video data streams. Naturally it is possible to ignore the video, but in that case one could also ask what was it worth to do it in the first place.</p>

<p>As if the situation would be just about the video. Several modern audio recorders, such as Edirol R-26, automatically produce as a number of audio files from different microphones. In order to work with this data in the most effective way we must somehow take this into account, as an example, by remixing the audio in way that brings up the best aspects of these distinct audio tracks, and recording in such a manner that we actually get the benefit that is there.</p>

<p>The days of having just one track of audio are over. Are we winning or losing with these changes, that is to be seen. But not taking them into account is an ignorance we cannot afford.</p>

<!--more-->

<p>I assume that each part in the presented workflow will change in some point. The technology changes always, and there is no reason to stick into old if some better solution is around. This said, we should not end up using any solutions which we are not thoroughly familiar with. At the same time, it remains the fact that many of our tools are used the most while we are doing fieldwork, which also means that we learn very much about them on the field.</p>

<h2 id="the-raw-data">The raw data</h2>

<p>As mentioned, the session raw data is getting wilder and wilder. Often we use several microphones, i.e. some lapel mics + one in a boompole to capture the overall sound. Also the camera makes its own audio track, which may be very usable in many cases. With many cameras this audio is also 6 channel surround, with which we have to consider are all those tracks containing what we want in the best possible constellation. Another thing to note is that many video cameras store their audio in Dolby Digital format which is not particularly transparent. Similarly, the video may be captured in AVCHD format, which also contains it’s own particularities.</p>

<p>Generally speaking in documentary linguistics it has been getting more and more common to capture also video. This also turns it into something one is expected to produce. In principle using two cameras is not out of the question, as it solves many problems there inherently are with the camera angle. One can be used to capture the general overview of the setting, and this gives to the other one more freedom to move around and get experimental. This is where the human component comes in. When we start to zoom camera into something that could be interesting, there is always the danger that <strong>the interesting</strong> takes place somewhere else. If we use only one camera we have to be careful, but with two there is already more freedom.</p>

<p>So a normal recording session contains very often at least the several files:</p>

<ul>
  <li>few audio files</li>
  <li>few video files</li>
  <li>scan from fieldnotes</li>
  <li>metadata files</li>
  <li>photographs of the informants</li>
  <li>general photograph or screenshot from the recording setting itself</li>
</ul>

<p>In practise the metadata can often be in a database and not in the actual folder with the session raw data, but this is not really the point here.</p>

<p>However, there are many steps before we actually can start to work with this data.</p>

<h2 id="data-processing">Data processing</h2>

<p>There are few steps one has to take with the raw data.</p>

<ul>
  <li>synchronization</li>
  <li>mixing</li>
  <li>cutting</li>
</ul>

<p>This is sort of a post-production phase which has not existed traditionally, but nowadays is there all the time. I’ve been using <strong>PluralEyes</strong> and <strong>Final Cut Pro X</strong> to do this. There are certainly other alternatives, but as far as I know there aren’t really open source solutions for this.</p>

<h3 id="pluraleyes">PluralEyes</h3>

<p>What PluralEyes does is to take all the audio and video files and to look for matching segments in the audio spectrograms. This must be very similar to audio fingerprinting tools, used i.e. with Python library DejaVu. However, good side of PluralEyes is that it is easy and fast. It also exports the synchronization metadata as an XML file.</p>

<h3 id="final-cut-pro">Final Cut Pro</h3>

<p>Final Cut Pro is a commercial video editing software, used widely by different video professionals and amateurs alike. I guess Adobe Premiere does more or less the same job equally well. Also Final Cut Pro allows us to import and export session data as an XML file, by the way.</p>

<p>In PluralEyes we don’t really do anything for the files, but in Final Cut Pro we can start to play more with them. Naturally, the question of cutting is very acute. Are we supposed to cut? What kind of videos are we doing as documentary linguists? Well, I guess the answer is that we are doing different videos for different uses. As an example, for a DVD that is sent to informant I may do different cuts than I do for the one that will be transcribed.</p>

<p>At least we have good rationale to cut something away from the beginning and the end, as this often has some noise from setting up the tools and preparing for the session. The main reason to cut, in my opinion, is that often this part is captured by one of the devices, i.e. there is an audio track, but the video camera is just being set up. So it just makes it nicer if we leave that hassle out. On the other hand, this often contains very critical information about how the aims and goals of the session are explained to the informant, how the linguists negotiated among each others who stays where, how the room was rearranged to make recording work better etc. These things do influence the recording quite a lot, so it is very good if that part of the work is also documented. However, should that be part of the transcribed session? Maybe. Should that be sent to the informant who maybe just wants to have a nice DVD with the actual interview?</p>

<p>Another example is that often the recording is interrupted and the technology is turned off for some time. As an example, we may turn camera and recorder off during a phone call or if someone has to leave for some personal errands. However, it is very important question can we just glue these two pieces together, or should we split these two into two different sessions? I’ve always split them into two, since I think the idea of a session is to represent one temporally consecutive situation. However, if the breaks are somehow very well indicated, I believe there is very little reason not to play around with these things if there is the need. One need would be to make an actually nice video from shorter video and audio recordings which are somehow topically interrelated. This is also nicer to transcribe and watch than treating each little file as their own session.</p>

<p>Of course the Final Cut Pro XML files contain data about the ways how files are rearranged and cut.</p>

<h3 id="note-about-xml-files">Note about XML files</h3>

<p>Naturally it is one thing to archive the XML files produced by these programs and actually do something useful with them. Understanding their structure and actually getting information out from them is not always trivial either. There are no real applications at the moment that would really use this data, similarly, I don’t think it has been very common practise to archive XML files like these. However, I think the only way we can excuse the use of commercial software is to make certain that the data is not locked into these systems. In any points. Certainly, the most comfortable way to work with fcpxml files is to open them in Final Cut Pro. But we have to make sure that is not the only option.</p>

<h2 id="audio-mixing">Audio mixing</h2>

<p>I must admit that I have no education about this topic. Maybe I should, as I’m a linguist who works with this stuff all the time, but I think there are very few instances of linguistic departments which include audio engineering as a part of their curricula.</p>

<p>I sort of thought I had got it already work nicely, but then one musician friend of mine was listening some ELAN sessions and complained about an echo. Yes, indeed, several audio tracks played simultaneously make sort of a nice sound where everyone can be heard well, but there was indeed some small echo. I remixed the tracks differently, putting some more quiet, some louder, and the echo disappeared. Not that I would understand anything about the process, but clearly this is an enormous field someone should understand about.</p>

<p>The situation is even more acute when it comes to work with old recordings. The sound quality is often quite bad, and there are certainly things we can do. I’ve used often ReaFir effect in REAPER to mute some frequencies, though there has been no way to include any audio editing software into the current workflow I have with documentary linguistic sessions. As our modern recordings are almost always very decent there is maybe little space for this, but still the question remains that mixing these audio channels from different devices is not trivial task at all.</p>

<p>This also means that it has to be very well indicated which are the actual raw data files and which are mixed for actual session. Naturally for phonetic analysis one should consult the raw data, but what you get into ELAN is usually a mix of several audio files, I see no other alternative.</p>

<h2 id="processed-data">Processed data</h2>

<p>So now the session folder actually contains already these files:</p>

<ul>
  <li>few audio files</li>
  <li>few video files</li>
  <li>scan from fieldnotes</li>
  <li>metadata files</li>
  <li>photograhps of the informants</li>
  <li>general photograph or screenshot about the recording setting itself</li>
  <li>PluralEyes XML</li>
  <li>Final Cut Pro XML</li>
  <li>audio file for ELAN</li>
  <li>video file for ELAN</li>
  <li>ELAN file</li>
</ul>

<p>What I have been doing now is to create new folders for different outputs, i.e. I have folder called session_name-i for the file version that has been sent for the informant, that often contains just a DVD disc image. Then there are folders marked with a, b, and c etc. for distinct subsessions if they exist. Usually they do. One problem is that the session can be understood to work out so that if the beginning hassle counts as something of its own, then that’s the part a. Then the actual recording, if uninterrupted, gets the symbol b, and the end hassle is c. So then there is a very large amount of sessions with the symbol b in their name, which feels bit stupid at times, but doesn’t really matter so much. Maybe there are better ways to arrange these files.</p>

<h2 id="whats-the-point">What’s the point?</h2>

<p>My idea about this workflow is such, that this would be ready for every session when we leave the fieldsite. If we have several video files, this version can be done with the most simple and general video there is. Don’t worry about nice video for the informants, that can be polished and sent back later. Quality wins over speed in that. For the later use it is possible to remix the video with different angles, this doesn’t influence the ELAN file of course in any way, unless there is actual mixing of the content, problems of which I already discussed briefly.</p>

<p>I already keep track from all metadata on the field, and make sure that everything is arranged into their own folders and metadata is filled up, if possible, at the same evening. More days pass more difficult it gets to actually reconstruct what has happened. I think actually taking it as far as even exporting the media for ELAN files and creating those dummy ELAN files does make sense. If this video management workflow is not taken care of instantly, it will become an enormous burden for someone (I’ve been that someone for several times). Running through this workflow is not very slow in the end, the only slow part is exporting. So process the session data at the evening with a beer or the local mildly alcoholic beverage of choice, leave the computer export and backup over night, repeat. If you have a research assistant or someone else doing this, make sure they are unstressed and have the beverage they deserve, this is not easy work, but it is worth doing on the spot.</p>

<p>I understand this workflow probably doesn’t work in locations where electricity is scarce. I work mainly in the Northern Russia, and there the villages are often very good locations for using computer at the evenings. I understand this is not always possible also time-wise, but my advice would be not to let this kind of work accumulate. I’ve spent months working with video and audio files from few weeks long fieldtrip, and very big part of that could had been ready even before I got back home.</p>

<h2 id="is-anything-going-to-change">Is anything going to change?</h2>

<p>Maybe when the computers get faster also video exporting gets faster, though this is unlikely as the video probably gets larger at the same rate. Maybe in some point it gets convenient enough to make notes straight away in digital format. This would change a lot, if one could, as an example, timestamp the notes and associate them with the raw data.</p>

<p>There has been this development that there is more and more fieldwork equipment. Two cameras means two tripods, and so on. However, there are some interesting developments. As an example, there have been lately more and more camera models which have a high quality objective in very small body. Naturally, one could assume that cameras like these are very good in video, as modern DSLR’s tend to be, and the small size makes them much more user-friendly. Now there are lots of hipstery retro models out there, but in some point we probably start to see products that could be immediately useful for documentary linguists as well. Just a note, in this workflow the video needs only some audio, it can be really bad even, just enough that it can be synchronized with the audio files.</p>

<p>The majority of events we record tend to be interviews of some sort. They are in many ways near conversations, but there is often the setting that one tells and another asks. Even when there are multiple participants it is normal that someone takes a very central role and does the most of the speaking. It isn’t fully solved how to record more naturally occurring speech events, usually luck has something to do with that. I think one change in the thinking would be to realize that now we basically record people when they are supposed to say something. Instead we maybe should record people when they do something, and if we are lucky, they say something. This means that we would end up recording much more situations where no one actually says a thing. I’m not currently certain how to move forward with that, but I’m sure the coming years will be interesting.</p>

<p>Of course it is very interesting if we would have recordings that last many hours and contain only few utterances. Why not. Hard disk space is cheap. These languages being used naturally is priceless.</p>

    <p id="post-meta"> <i class="fa fa-tags"></i> </p>
  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">
        <figure>
              <center><img src="/media/logo/kone_logo_web.png" width="400px"></center>
        </figure>
    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li><a href="mailto:barentsdoc@gmail.com">barentsdoc@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/langdoc">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">langdoc</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/nikopartanen">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">nikopartanen</span>
            </a>
          </li>
          
        </ul>
      </div>
      <div class="footer-col  footer-col-3">
        <p class="text" style="font-size:80%">  This website has been done in within <a href="http://www.koneensaatio.fi/en/">Kone Foundation</a> funded research project Izhva Komi Language Documentation. The project is led by <a href="mailto:rogier.blokland@moderna.uu.se">Rogier Blokland, <a href="mailto:m.riessler@gmail.com">Michael Rießler</a> and <a href="mailto:fedinamarina@gmail.com">Marina Fedina</a>.</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
